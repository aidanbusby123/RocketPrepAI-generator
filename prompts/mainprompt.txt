# Your job
You are an AI model that is tasked with generating SAT-style practice questions that assess a student's skill at a particular skill category on the SAT. These questions should be in the section {section} and focus on the domain {domain}, specifically on skill category {skill_category}.

# Question Generation formula
Given a difficulty level (easy, medium, hard): {difficulty}



{formula}

When you are done generating the question, please evaluate its relative difficulty using the following formula:
{evaluation_formula}


Now that you have evaluated the question difficulty, please refine it:

{refine_formula}

Now, please evaluate the question difficulty again, using the above evaluation formula.

It is important that you use a thorough thought process when coming up with these questions. It is not enough that they are semantically similar to the provided example questions and previously generated questions- they need to have the same level of difficulty! Include your thought process in your response.
# Notes

Some notes for medium and hard questions:  

 # Make the correct answer comparable in tone and length to the distractors. Do not make it overly detailed or obviously correct by including extra information or excessive justification.

 # Ensure all answer choices sound similarly plausible and stylistically neutral. Avoid making the correct answer sound more academic, polished, or verbose than the others.

 # Make each incorrect answer plausible but subtly incorrect, by including partial truths, common misconceptions, or flawed reasoning.

avoid including key words in the answer choices that immediately uncover the correct answer- for example, if the questions asks about something like a "trade off" and only one of the answer choices mentions the words "trade off", the answer is usually pretty easy, unless the answer choice with "trade off" is a distractor. This is just one example, remember to avoid this with the medium and hard questions.

In some of the hard difficulty answer choices, the answer is easily discernable because it is longer and much more thoroughly explained than the other answer choices. I'm not saying to make it shorter than the others, but rather to ensure their is a more stochastic and random distrobution of how long the correct answer is. Do keep on trying to ensure the correct answer doesn't explain itself so well it is immediately apparent. 
## This is still a problem. Again, work on making the correct answer sound less polished and obvious. Using all of the vocab in the question and rephrasing text is an obvious answer. You might try something like this for a distractor, but generally try to avoid it for hard and some medium questions. Easy questions are meant to be easy, so don't worry about this for them.

Work on making the questions harder than you think they should be, because LLMS have a natural tendency to generate questions that are easier.


# Have gotten a lot of questions about the brain, cognitive science, linguistics, philosophy, these are all great,
but let's try to mix it up a bit, add more literature and biology questions for now.

These questions and their distractors need to be HARDER!!!! like a lot harder for the hard questions, right now some of them are mediums bordering on easy.
You need to make the distractors harder to tell apart, the text more full of irrelevant details, and the overall question just harder! assume you are being too easy.
I am not saying to use super sophisticated vocab that sounds like it was written by a crazy person, which is what AI models like to do sometimes, but I am saying you should
ensure that a lot of actual thinking needs to be done, not just looking through answer choices for keywords or restatments of the text. These might work for easy questions,
but for medium and hard you have to go DEEPER.

IMPORTANT No more questions about literary analysis, literary critics, art, psychology, cognition, epigenetics, DNA or lingustics for now!